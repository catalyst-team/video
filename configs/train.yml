model_params:
  model: tsn

  base_model:
    partial_bn: null
    arch: resnet18
    pretrained: true
    frozen: true
    pooling: GlobalConcatPool2d

  tsn_model:
    feature_net_hiddens: 128
    emb_net_hiddens: 128
    consensus: ["avg", "max", "attention"]
    num_classes: &num_classes 4
    activation_fn: ReLU
    norm_fn: BatchNorm1d
    bias: false
    dropout: 0.5

args:
  expdir: "tsn"
#  logdir: ./logs
  baselogdir: ./logs # for grid search

stages:
  state_params:
    main_metric: &reduce_metric  auc_class/_mean
    minimize_metric: False

  criterion_params:
    criterion: FocalLossMultiClass # CrossEntropyLoss

  data_params:
    num_workers: 4
    batch_size: 4
    per_gpu_scaling: True

    num_frames: 5
    time_window: 1
    uniform_time_sample: true
    tag2class: "./data/labeling.json"
    tag_column: "video"
    class_column: "class"
    datapath: "./data/video_dataset_processed"
    in_csv_train: "./data/train_fold_0.csv"
    in_csv_valid: "./data/valid_fold_0.csv"
    in_csv_infer: "./data/valid_fold_0.csv"
    one_hot_classes: *num_classes


  callbacks_params:
    loss_class:
      callback: CriterionCallback
      input_key: targets
      output_key: logits
      prefix: loss_class
#      criterion_key: class

    accuracy_class:
      callback: AccuracyCallback
      input_key: targets
      output_key: logits
      prefix: accuracy_class
      num_classes: *num_classes
    auc_class:
      callback: AUCCallback
      input_key: targets_one_hot
      output_key: logits
      prefix: auc_class
      num_classes: *num_classes
    f1_class:
      callback: F1ScoreCallback
      input_key: targets_one_hot
      output_key: logits
      activation: Softmax
    cm_class:
      callback: ConfusionMatrixCallback
      input_key: targets
      output_key: logits
      prefix: cm_class
      num_classes: *num_classes

    optimizer:
      callback: OptimizerCallback
      loss_key: loss_class
    scheduler:
      callback: SchedulerCallback
      reduce_metric: *reduce_metric
    saver:
      callback: CheckpointCallback

  stage_head_train:
    state_params:
      num_epochs: 10

    optimizer_params:
      optimizer: Adam
      lr: 0.001
      weight_decay: 0.0005

    scheduler_params:
      scheduler: MultiStepLR
      gamma: 0.5
      milestones: [5]

  stage_full_finetune:
    state_params:
      partial_bn: 2
      num_epochs: 20

    optimizer_params:
      optimizer: SGD
      momentum: 0.9
      lr: 0.001
      weight_decay: 0.0005

    scheduler_params:
      scheduler: MultiStepLR
      gamma: 0.1
      milestones: [10]
